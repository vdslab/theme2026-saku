# トーラス階層割当の数理計画定式化

## 問題設定

有向グラフ $G = (V, A)$ が与えられたとき、各ノードに階層を割り当て、階層が減少する辺（トーラス辺）を最小限に抑えながら、階層構造を最適化する。

### 入力

- $V$: ノード集合
- $A \subseteq V \times V$: エッジ集合
- $w: A \rightarrow \mathbb{R}^+$: エッジ重み（デフォルト: すべて1）
- $\lambda: A \rightarrow \mathbb{Z}^+$: エッジの最小階層差（デフォルト: すべて1）
- $\alpha, \beta \in \mathbb{R}^+$: 目的関数の重みパラメータ

### 定数

- $n = |V|$: ノード数
- $M = n$: Big-M定数（十分大きな値）

## 変数

| 変数       | 型                            | 説明                                                   |
| ---------- | ----------------------------- | ------------------------------------------------------ |
| $y_v$      | $\in \\{0, 1, \ldots, n-1\\}$ | ノード $v$ の階層 $\forall v \in V$                    |
| $t_{uv}$   | $\in \\{0, 1\\}$              | エッジ $(u,v)$ がトーラス辺なら1 $\forall (u,v) \in A$ |
| $L_{\max}$ | $\in \\{0, 1, \ldots, n-1\\}$ | 使用される最大階層数                                   |

## 制約条件

### 1. 最大階層の定義

```math
y_v \leq L_{\max} \quad \forall v \in V
```

すべてのノードの階層が最大階層数以下であることを保証。

---

### 2. トーラス辺の定義（Big-M法）

**トーラス辺の条件**: $t_{uv} = 1 \Leftrightarrow y_u > y_v$

この条件を以下の2つの不等式で表現：

#### 制約 (a)

```math
y_u - y_v \leq M \cdot t_{uv} \quad \forall (u,v) \in A
```

**解釈:**

- $t_{uv} = 0$ のとき: $y_u \leq y_v$（通常辺の場合、始点の階層 ≤ 終点の階層）
- $t_{uv} = 1$ のとき: 制約は緩い（$y_u - y_v \leq M$ は常に成立）

#### 制約 (b)

```math
y_u - y_v \geq 1 - M \cdot (1 - t_{uv}) \quad \forall (u,v) \in A
```

**解釈:**

- $t_{uv} = 1$ のとき: $y_u \geq y_v + 1$（トーラス辺の場合、始点の階層 > 終点の階層）
- $t_{uv} = 0$ のとき: 制約は緩い（$y_u - y_v \geq 1 - M$ は常に成立）

---

### 3. 通常辺の階層制約

```math
y_v - y_u \geq \lambda_{uv} - M \cdot t_{uv} \quad \forall (u,v) \in A
```

**解釈:**

- $t_{uv} = 0$ のとき: $y_v \geq y_u + \lambda_{uv}$（通常辺の最小階層差を保証）
- $t_{uv} = 1$ のとき: 制約は緩い（トーラス辺には適用されない）

---

## 目的関数

```math
\min \quad \alpha \cdot L_{\max} + \beta \cdot \sum_{(u,v) \in A} w_{uv} \cdot (y_v - y_u + M \cdot t_{uv})^2 + \gamma \cdot \sum_{(u,v) \in A} t_{uv}
```

### 目的関数の解釈

1. **第1項** $\alpha \cdot L_{\max}$: 階層数を最小化
2. **第2項** $\beta \cdot \sum_{(u,v) \in A} w_{uv} \cdot (y_v - y_u + M \cdot t_{uv})^2$: エッジスパンの2乗（分散）を最小化
   - $t_{uv} = 0$（通常辺）のとき: $(y_v - y_u)^2$
   - $t_{uv} = 1$（トーラス辺）のとき: $(y_v - y_u + M)^2$（非常に大きなペナルティ）
3. **第3項** $\gamma \cdot \sum_{(u,v) \in A} t_{uv}$: トーラス辺の数を直接最小化

### 2乗形式を使う理由

- **長いエッジに対する強いペナルティ**: 線形の場合と比べ、スパンが大きいエッジに対してより強いペナルティを課す
- **均等なエッジ長の促進**: エッジスパンのばらつきを抑え、より均一な階層構造を生成
- **Big-M法との相性**: トーラス辺（$t=1$）の場合、$(y_v - y_u + M)^2 \approx M^2$となり、極めて大きなペナルティとなる

トーラス辺に大きなペナルティ（第2項と第3項）を課すことで、DAGの場合は極力トーラス辺を使用しない。

## 完全な定式化

```math
\begin{align}
\min \quad & \alpha \cdot L_{\max} + \beta \cdot \sum_{(u,v) \in A} w_{uv} \cdot (y_v - y_u + M \cdot t_{uv})^2 + \gamma \cdot \sum_{(u,v) \in A} t_{uv} \\
\text{subject to} \quad & y_v \leq L_{\max} && \forall v \in V \\
& y_u - y_v \leq M \cdot t_{uv} && \forall (u,v) \in A \\
& y_u - y_v \geq 1 - M \cdot (1 - t_{uv}) && \forall (u,v) \in A \\
& y_v - y_u \geq \lambda_{uv} - M \cdot t_{uv} && \forall (u,v) \in A \\
& y_v \in \{0, 1, \ldots, n-1\} && \forall v \in V \\
& t_{uv} \in \{0, 1\} && \forall (u,v) \in A \\
& L_{\max} \in \{0, 1, \ldots, n-1\}
\end{align}
```

## パラメータのデフォルト値

| パラメータ     | デフォルト値 | 説明                           |
| -------------- | ------------ | ------------------------------ |
| $\alpha$       | 100          | 階層数の最小化を優先           |
| $\beta$        | 1            | エッジスパンの最小化は副次的   |
| $\gamma$       | 1000         | トーラス辺数の最小化を強く優先 |
| $w_{uv}$       | 1            | すべてのエッジ重みは等しい     |
| $\lambda_{uv}$ | 1            | 通常辺の最小階層差は1          |

## 実装例

### Python (Gurobi)

```python
from torus import torus
from draw_torus import draw_torus

# グラフの定義
V = [0, 1, 2]
A = [(0, 1), (1, 2), (2, 0)]

# 階層割当の最適化
y_val, t_val, L = torus(V, A)

# 結果の可視化
draw_torus(V, A, L)
```

### 出力

```
最適化成功!
最大階層数: 2
トーラス辺の数: 1
目的関数値: 1203.00

階層割当: {0: 0, 1: 1, 2: 2}
トーラス辺: [(2, 0)]
通常辺: [(0, 1), (1, 2)]
```

### DAGの場合

```python
# DAGのテスト
V = [0, 1, 2, 3, 4]
A = [(0, 1), (0, 2), (1, 3), (2, 3), (3, 4)]
y_val, t_val, L = torus(V, A)
```

**出力:**

```
最適化成功!
最大階層数: 3
トーラス辺の数: 0
目的関数値: 305.00

階層割当: {0: 0, 1: 1, 2: 1, 3: 2, 4: 3}
トーラス辺: []
通常辺: [(0, 1), (3, 4), (2, 3), (0, 2), (1, 3)]
```

DAGの場合、トーラス辺を使用する必要がないため、トーラス辺の数は0になる。

## アルゴリズムの特徴

### 長所

- ✅ 階層数を最適化変数として自動決定
- ✅ トーラス辺を自動的に判定
- ✅ DAG、サイクリックグラフ、混合グラフに対応
- ✅ ソース頂点・シンク頂点を持つグラフにも対応
- ✅ 厳密解を保証（整数計画法）

### 制約

- ⚠️ Big-M法を使用しているため、大規模グラフでは計算時間が増加する可能性
- ⚠️ 階層数が多い場合、変数と制約の数が増加

## テスト結果

22件のテストケースすべてで最適化に成功（成功率100%）：

- 手動定義テストケース: 6件
- 自動生成テストケース: 12件
- エッジケーステスト: 4件

詳細は `test_torus.py` を参照。
